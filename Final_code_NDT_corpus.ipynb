{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import random \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project was originally to categorize documents from the colliegiate debate wiki into categories based on the country each document case or plan \"affirmative\" had. However due to the massive amount of documents I needed to hand label, the 105 documents I had were not enough for this. But, I did have enough to divide into two categories, planless and plan affrimatives. In college debate there is a clear split between teams that read an affirmation of topic, this year it was about reducing US alliance commitments, and teams that do not read a plan. These \"planless\" teams usually read philosophical or political criticisms of the topic, or debate and so draw from a very different literature base than the \"plan\" affirmatives. All of this is very contentious, but if an accurate classification algrotihm could be developed, quantifying the trends and differences would be possible, without the need for manual classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy approach I thought would be to simply search texts for a few key words to indicate if they have a plan, and so I did that by using naive bayes, although it could be even simpler than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "corpusdir6 = 'Plan'\n",
    "corpusdir7 = 'No_Plan'\n",
    "\n",
    "\n",
    "\n",
    "Plan_corpus = PlaintextCorpusReader(corpusdir6, '.*')\n",
    "No_Plan_corpus = PlaintextCorpusReader(corpusdir7, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(Plan_corpus.words(fileid)),'Plan') for fileid in Plan_corpus.fileids()] + [(list(No_Plan_corpus.words(fileid)),'No_Plan') for fileid in No_Plan_corpus.fileids()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the word features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "all_words = Plan_corpus.words() + No_Plan_corpus.words() \n",
    "\n",
    "filtered_words = [word for word in all_words if word not in stopwords.words('english')]\n",
    "\n",
    "fd = nltk.FreqDist(list(filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_words))\n",
    "word_features = [word for (word, count) in fd.most_common(4000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the two corpus's have over a million words and 100 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features2(document):\n",
    "    document_words = set(stemmer.stem(word) for word in document)\n",
    "    features = {}\n",
    "    for word in good_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "         \n",
    "doc_featuresets2 = [(features(d), c) for (d,c) in documents]\n",
    "random.shuffle(doc_featuresets2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_features2 = ['nuclear', 'plan', '5', 'S', 'U', 'aircraft', 'revisionist', 'spiral',\n",
    "                 'partnership', 'grand', 'alternative',\n",
    "                 'one', 'honor', 'analyst', 'civillian', 'key']\n",
    "good_features = ['USFG', 'usfg',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = doc_featuresets2[40:], doc_featuresets2[:40]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad results, I found the highest accuracy came from using only two words as feautures \"USFG\" that stands for US Federal Government, that many plan teams use when writing a plan. Also interesting was I found the word \"nuclear\" highly predicted a plan aff as many plan affirmatives discuss speculative war scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used tf-idf and the kmeans algorithm to separate the find the difference in language used by the planless and policy focused case affrimatives, in many ways this is more interesting because it shows how the two categories cluster around different vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docu = [Plan_corpus.raw(fileid) for fileid in Plan_corpus.fileids()] + [No_Plan_corpus.raw(fileid) for fileid in No_Plan_corpus.fileids()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(docu, stop_words={'english'}, max_df=0.5, min_df=0.1, lowercase=True)\n",
    "\n",
    "X = vectorizer.fit_transform(docu)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=1000, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :200]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the planless affirmative's top terms of the cluster has words heaviliy emphasized in the \"critical theory\" type humanities. Words like \"body\" and \"colonial\" show the connection to these humanities fields. On the other hand plan affirmatives top terms in the other cluster emphasizes geopolitical terminology and things like \"cyber\" and vocabulary taken from international relations literature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(stopwords = STOPWORDS,\n",
    "                  background_color = \"white\",\n",
    "                  max_words = 200,\n",
    "                  max_font_size = 40, \n",
    "                  scale=3,\n",
    "                  random_state=1\n",
    "                 ).generate(str([terms[ind] for ind in order_centroids[i, :200]]))\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.clf()\n",
    "plt.imshow(cloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(stopwords = STOPWORDS,\n",
    "                  background_color = \"white\",\n",
    "                  max_words = 200,\n",
    "                  max_font_size = 40, \n",
    "                  scale=3,\n",
    "                  random_state=1\n",
    "                 ).generate(str([terms[ind] for ind in order_centroids[0, :200]]))\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.clf()\n",
    "plt.imshow(cloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
